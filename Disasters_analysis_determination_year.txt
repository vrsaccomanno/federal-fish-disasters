# Brice X. Semmens, 04/16/20

# Statistics to be done:
# 1) Evalute change in disaster frequency as function of declaration year
# Approach: Poisson regression with number of declared disasters per year 
# as response variable, and year as the explanatory variable. 
# You could account for region as a random or fixed effect. 
#
# Hereâs a definition of each of field in the dataset:
#Disaster Number: The federal ID number given on the NOAA website
#Fishery(ies): The fishery or fisheries listed on the NOAA website
#State: State(s) or territories listed on the NOAA website
#Management Zone: NOAA Fisheries management region
#Determination Year: The year that each disaster was federally determined
#Impact year(s): The year(s) in which each disaster actually occurred
#Disaster Cause: The causes of disasters condensed into three broad categories
#Appropriation amount (2019 USD): Amount appropriated by Congress
#Net Revenue Change (2019 USD): Change in ex-vessel revenue during the disaster year relative to the previous 5-year average
#State-years: number of states and years impacted in each disaster

setwd("C:/Users/LYALL.BELLQUIST/Box/Climate Ready Fisheries/New Papers/Federal Fisheries Disasters - Extreme event normalization/Figures/Brice Figures/Data from Brice/Newest Data from Brice")
library(tidyverse)
library(ggplot2)
library(lme4)
library(tidyr)
library(dplyr)
library(dplyr, warn.conflicts = FALSE)

### BRING IN DATA ####################################################################
# First let's read in the raw data file (observation records in flat format)
d.data <- read.csv("Disaster_Summary_Data_forBrice.csv", header = T)

# let's make a dataframe with # designated disasters per year per region (missing 0s)
D.r <-as.data.frame(d.data %>%
                     group_by(Management.Zone,Determination.Year) %>%  
                     summarize( Disasters=n()))     # Grouping by year and zone

# Now add in the zeros (years where no disasters happened)
D.z<-as.data.frame(D.r %>% group_by(Management.Zone) %>% 
  complete(Determination.Year = seq(min(Determination.Year), 
  max(Determination.Year)),fill = list(Disasters = 0)) )

# first scale year to aid in convergence
D.z$scaled.d.Year<-as.vector(scale(D.z$Determination.Year))

# Let's now fit a Poisson mixed model 
 library(lme4)
m.mix<-glmer(Disasters ~ scaled.d.Year + (1|Management.Zone), data=D.z,family=poisson(link="log"))
summary(m.mix)

# let's do fixed effect of year only (assume counds IID across Management.Zone)
# First we need to geneate the required data frame for analysis

# let's make a dataframe with # designated disasters per year per region (missing 0s)
D <-as.data.frame(d.data %>%
                    group_by(Determination.Year) %>%  # Grouping by year
                    summarize( Disasters=n()))

# Now add in the zeros (years where no disasters happened)
D.fix<-as.data.frame(D %>% 
                complete(Determination.Year = seq(min(Determination.Year), 
                max(Determination.Year)),fill = list(Disasters = 0)) )

# first scale year to aid in convergence
D.fix$scaled.d.Year<-as.vector(scale(D.fix$Determination.Year))
# Poisson seems reasonable given mean and var of D.fix$Disasters are essentially identical
m.fix <- glm(Disasters ~ scaled.d.Year, data=D.fix, family = poisson(link = "log"))
summary(m.fix) #significant (p~0.005) for the effect of Determination year on # of disasters

# ok cool, let's plot with confidence interval:
g0 <- ggplot(D.fix,aes(x=Determination.Year,y=Disasters))
glm1<-g0+geom_point()+geom_smooth(method="glm", method.args = list(family = "poisson"), 
       se=TRUE, fill = "skyblue1")+xlab("Year")+ylab("Number of Disasters")+ theme_bw()
glm1
